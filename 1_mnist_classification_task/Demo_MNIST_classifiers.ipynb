{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import functools\n",
        "from abc import abstractmethod\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras import layers, Input\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class MnistClassifierInterface:\n",
        "  \"\"\"\n",
        "  Interface for the MNIST classifiers\n",
        "  \"\"\"\n",
        "  MAX_PIXELS = 255.0\n",
        "  NUM_CLASSES = 10  # number of values overall in MNIST dataset\n",
        "\n",
        "  @abstractmethod\n",
        "  def train(self, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Run train data process\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  @abstractmethod\n",
        "  def predict(self, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Run predict data process\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.__class__.__name__\n",
        "\n",
        "\n",
        "class RandomForest(MnistClassifierInterface):\n",
        "  \"\"\"\n",
        "  A Random Forest classifier for MNIST image recognition tasks\n",
        "  \"\"\"\n",
        "  def __init__(self, X_train, X_test, y_train, y_test, *args, **kwargs) -> None:\n",
        "    self.X_train = X_train\n",
        "    self.X_test = X_test\n",
        "    self.y_train = y_train\n",
        "    self.y_test = y_test\n",
        "    self.model = RandomForestClassifier()\n",
        "\n",
        "  def train(self, *args, **kwargs) -> float:\n",
        "    \"\"\"\n",
        "    Train model and return accuracy score\n",
        "    \"\"\"\n",
        "    self.model.fit(self.X_train, self.y_train)\n",
        "    accuracy = self.model.score(self.X_test, self.y_test)\n",
        "    return accuracy\n",
        "\n",
        "  def predict(self) -> float:\n",
        "    \"\"\"\n",
        "    Get model prediction results and return accuracy score\n",
        "    \"\"\"\n",
        "    y_pred = self.model.predict(self.X_test)\n",
        "    accuracy = accuracy_score(y_pred, self.y_test)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "class FeedForwardNeuralNetwork(MnistClassifierInterface):\n",
        "  \"\"\"\n",
        "  A Feed-Forward Neural Network (FNN) classifier for MNIST image recognition tasks\n",
        "  \"\"\"\n",
        "  def __init__(self, X_train: pd.DataFrame, X_test: pd.DataFrame,\n",
        "               y_train: pd.DataFrame, y_test: pd.DataFrame,\n",
        "               epochs: int=5) -> None:\n",
        "    self.X_train = self._normalize_input(X_train)\n",
        "    self.X_test = self._normalize_input(X_test)\n",
        "    self.y_train = self._convert_to_categorical(y_train)\n",
        "    self.y_test = self._convert_to_categorical(y_test)\n",
        "\n",
        "    self.epochs = epochs\n",
        "    self.model = self._get_model()\n",
        "\n",
        "  def _normalize_input(self, data: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalize input data. Applicable for X_train, X_test.\n",
        "    No need to reshape for FNN, since we already get data as one long vector 784.\n",
        "    \"\"\"\n",
        "    normalized = data / self.MAX_PIXELS\n",
        "    return normalized\n",
        "\n",
        "  def _convert_to_categorical(self, data: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert labels into one-hot encoded vectors. Applicable for y_train, y_test.\n",
        "    \"\"\"\n",
        "    encoded = to_categorical(data, self.NUM_CLASSES)\n",
        "    return encoded\n",
        "\n",
        "  def _get_model(self) -> Sequential:\n",
        "    \"\"\"\n",
        "    Create model for the classifier\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(self.X_train.shape[1],)))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=64, activation='relu'))\n",
        "    model.add(Dropout(0.25))  # reduce overfitting\n",
        "    model.add(Dense(units=self.NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def train(self, batch_size=256) -> float:\n",
        "    \"\"\"\n",
        "    Train model and return accuracy score\n",
        "    \"\"\"\n",
        "    self.model.fit(self.X_train, self.y_train, batch_size=batch_size, epochs=self.epochs)\n",
        "    _, accuracy = self.model.evaluate(self.X_test, self.y_test, batch_size=batch_size)\n",
        "    return accuracy\n",
        "\n",
        "  def predict(self) -> float:\n",
        "    \"\"\"\n",
        "    Get model prediction results and return accuracy score\n",
        "    \"\"\"\n",
        "    y_pred_probs = self.model.predict(self.X_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    accuracy = accuracy_score(y_pred, np.argmax(self.y_test, axis=1))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "class ConvolutionalNeuralNetwork(MnistClassifierInterface):\n",
        "  \"\"\"\n",
        "  A Convolutional Neural Network (CNN) classifier for MNIST image recognition tasks\n",
        "  \"\"\"\n",
        "  IMG_SIZE = (28, 28)  # width and height of the image\n",
        "\n",
        "  def __init__(self, X_train: pd.DataFrame, X_test: pd.DataFrame,\n",
        "               y_train: pd.DataFrame, y_test: pd.DataFrame,\n",
        "               epochs: int=5) -> None:\n",
        "    self.X_train = self._normalize_input(X_train)\n",
        "    self.X_test = self._normalize_input(X_test)\n",
        "    self.y_train = self._convert_to_categorical(y_train)\n",
        "    self.y_test = self._convert_to_categorical(y_test)\n",
        "\n",
        "    self.epochs = epochs\n",
        "    self.model = self._get_model()\n",
        "\n",
        "  def _normalize_input(self, data: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalize input data. Applicable for X_train, X_test.\n",
        "    Need to reshape for CNN, since we get data as one long vector 784, but we need 28*28\n",
        "    \"\"\"\n",
        "    normalized = data / self.MAX_PIXELS\n",
        "    res = normalized.values.reshape(-1, *self.IMG_SIZE)\n",
        "    return res\n",
        "\n",
        "  def _convert_to_categorical(self, data: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert labels into one-hot encoded vectors. Applicable for y_train, y_test.\n",
        "    \"\"\"\n",
        "    encoded = to_categorical(data, self.NUM_CLASSES)\n",
        "    return encoded\n",
        "\n",
        "  def _get_model(self) -> Sequential:\n",
        "    \"\"\"\n",
        "    Create model for the classifier\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(*self.IMG_SIZE, 1)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(layers.Dense(self.NUM_CLASSES, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  def train(self, batch_size=256) -> float:\n",
        "    \"\"\"\n",
        "    Train model and return accuracy score\n",
        "    \"\"\"\n",
        "    self.model.fit(self.X_train, self.y_train, batch_size=batch_size, epochs=self.epochs)\n",
        "    _, accuracy = self.model.evaluate(self.X_test, self.y_test, batch_size=batch_size)\n",
        "    return accuracy\n",
        "\n",
        "  def predict(self) -> float:\n",
        "    \"\"\"\n",
        "    Get model prediction results and return accuracy score\n",
        "    \"\"\"\n",
        "    y_pred_probs = self.model.predict(self.X_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    accuracy = accuracy_score(y_pred, np.argmax(self.y_test, axis=1))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "class MnistClassifier:\n",
        "  \"\"\"\n",
        "  Factory class to instantiate requested model\n",
        "  \"\"\"\n",
        "  @functools.cached_property\n",
        "  def mnist_data(self) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Cached property with MNIST data.\n",
        "    Object can be reused for different classifiers w/o reloading MNIST data.\n",
        "    \"\"\"\n",
        "    mnist = fetch_openml('mnist_784')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=1/7)  # setup for test data to be 1000 out of 7000\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "  def get_model(self, code: str) -> MnistClassifierInterface:\n",
        "    \"\"\"\n",
        "    Instantiate requested classifier\n",
        "    \"\"\"\n",
        "    classifiers = {\n",
        "        'cnn': ConvolutionalNeuralNetwork,\n",
        "        'rf': RandomForest,\n",
        "        'nn': FeedForwardNeuralNetwork,\n",
        "    }\n",
        "    if code in classifiers:\n",
        "      # X_train, X_test, y_train, y_test = self.mnist_data\n",
        "      return classifiers[code](*self.mnist_data)\n",
        "\n",
        "    raise ValueError(f'Got unexpected value: {code}. Expected values: {list(classifiers)}')\n",
        "\n",
        "\n",
        "def run_models():\n",
        "  \"\"\"\n",
        "  Run training and prediction for Random Forest, Feed-Forward Neural Network and Convolutional Neural Network models\n",
        "  and print results. When classifier created, it will read data on instantiation and later reuse cached data\n",
        "  as input for all 3 models (this improves performance, avoids re-loading data anew for each model).\n",
        "  \"\"\"\n",
        "  classifier = MnistClassifier()\n",
        "  algorithm_list = ['cnn', 'rf', 'nn']\n",
        "  acc_predict_model = {}\n",
        "\n",
        "  for code in algorithm_list:\n",
        "    start = time.perf_counter()\n",
        "\n",
        "    model = classifier.get_model(code)\n",
        "    print(f'Called {str(model)}')\n",
        "    acc_train = model.train()\n",
        "    acc_predict = model.predict()\n",
        "    acc_predict_model[str(model)] = acc_predict\n",
        "    print(f'>>> Training accuracy {acc_train}. Prediction accuracy {acc_predict}')\n",
        "\n",
        "    minutes, sec = divmod(time.perf_counter() - start, 60)\n",
        "    print(f'Time elapsed {minutes:0f} min {sec:.0f} sec')\n",
        "\n",
        "  sorted_acc = dict(sorted(acc_predict_model.items(), key=lambda item: item[1], reverse=True))\n",
        "  print(f'Accuracy score sorted by model: {sorted_acc} min')\n",
        "\n",
        "\n",
        "run_models()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLcCW5Sdvw4h",
        "outputId": "20dad518-ee4e-4240-d361-2a810031ab8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Called ConvolutionalNeuralNetwork\n",
            "Epoch 1/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 62ms/step - accuracy: 0.8252 - loss: 0.5965\n",
            "Epoch 2/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.9691 - loss: 0.1053\n",
            "Epoch 3/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.9788 - loss: 0.0706\n",
            "Epoch 4/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 65ms/step - accuracy: 0.9833 - loss: 0.0555\n",
            "Epoch 5/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 62ms/step - accuracy: 0.9868 - loss: 0.0425\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9839 - loss: 0.0462\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            ">>> Training accuracy 0.9858999848365784. Prediction accuracy 0.9859\n",
            "Time elapsed 1.000000 min 53 sec\n",
            "Called RandomForest\n",
            ">>> Training accuracy 0.9698. Prediction accuracy 0.9698\n",
            "Time elapsed 0.000000 min 43 sec\n",
            "Called FeedForwardNeuralNetwork\n",
            "Epoch 1/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7228 - loss: 0.9039\n",
            "Epoch 2/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.2153\n",
            "Epoch 3/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9553 - loss: 0.1533\n",
            "Epoch 4/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.1187\n",
            "Epoch 5/5\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0947\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9678 - loss: 0.0996\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            ">>> Training accuracy 0.9700999855995178. Prediction accuracy 0.9701\n",
            "Time elapsed 0.000000 min 8 sec\n",
            "Accuracy score sorted by model: {'ConvolutionalNeuralNetwork': 0.9859, 'FeedForwardNeuralNetwork': 0.9701, 'RandomForest': 0.9698} min\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}